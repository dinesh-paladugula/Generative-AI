| **Layer**           | **Tools / Tech Stack**                           | **What it is used for**            | **Why it is needed**                  |
| ------------------- | ------------------------------------------------ | ---------------------------------- | ------------------------------------- |
| Data Ingestion      | Unstructured.io, Apache Tika                     | Extract text from PDFs, DOCX, HTML | Handles diverse document formats      |
| Web Ingestion       | Scrapy, Playwright                               | Crawl and fetch website content    | Brings live web data into RAG         |
| ETL / Pipelines     | Python, Airflow                                  | Scheduled ingestion and processing | Automates updates                     |
| Chunking & Indexing | LangChain, LlamaIndex                            | Split and structure data           | Improves retrieval accuracy           |
| Text Embeddings     | OpenAI Embeddings, Sentence-Transformers, Cohere | Convert text to vectors            | Enables semantic search               |
| Image Embeddings    | CLIP, OpenAI Multimodal                          | Encode images as vectors           | Supports multimodal RAG               |
| Vector Database     | FAISS, Chroma, Pinecone, Weaviate, Milvus        | Store and search vectors           | Core retrieval engine                 |
| Keyword Search      | Elasticsearch, OpenSearch                        | Traditional text search            | Improves exact-match recall           |
| Hybrid Search       | Weaviate, OpenSearch                             | Vector + keyword search            | Best overall retrieval quality        |
| Re-ranking          | Cohere Rerank, Cross-Encoders                    | Reorder retrieved results          | Improves relevance before LLM         |
| Retriever Framework | LangChain, Haystack                              | Retrieval orchestration            | Simplifies retrieval logic            |
| LLM                 | GPT-4-class, Claude, Gemini, LLaMA               | Generate responses                 | Produces natural language output      |
| Prompt Management   | LangChain Prompts, PromptLayer                   | Template and version prompts       | Controls LLM behavior                 |
| Backend API         | FastAPI, Flask, Node.js                          | Serve RAG as an API                | Integration with apps                 |
| Streaming           | SSE, WebSockets                                  | Stream LLM responses               | Better UX and lower perceived latency |
| Frontend            | React, Next.js, Streamlit, Gradio                | User interface                     | Enables interaction                   |
| Authentication      | OAuth2, JWT, Cognito                             | Secure access                      | Protects enterprise data              |
| PII & Guardrails    | LLM Guard, Presidio                              | Mask sensitive data                | Compliance and safety                 |
| Observability       | LangSmith, Phoenix, W&B                          | Trace and debug RAG flows          | Improves reliability                  |
| Evaluation          | RAGAS, TruLens                                   | Measure RAG quality                | Prevents hallucinations               |
| Caching             | Redis                                            | Cache embeddings and answers       | Reduces cost and latency              |
| Infrastructure      | Docker, Kubernetes                               | Containerization & scaling         | Production readiness                  |
| Cloud               | AWS, GCP, Azure                                  | Compute and storage                | Scalable deployment                   |
| CI/CD               | GitHub Actions, GitLab CI                        | Automated builds & deploys         | Faster iteration                      |